{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Cin2DCEVm3jM"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7181891e3f2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# Import the libraries\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.4.1-cp38-cp38-win_amd64.whl (370.7 MB)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\oolus\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\oolus\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\oolus\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
      "  Using cached tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\oolus\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.15.1-py2.py3-none-any.whl (173 kB)\n",
      "Processing c:\\users\\oolus\\appdata\\local\\pip\\cache\\wheels\\5f\\fd\\9e\\b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\\wrapt-1.12.1-py3-none-any.whl\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\oolus\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Processing c:\\users\\oolus\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\\termcolor-1.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\oolus\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.2)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\oolus\\anaconda3\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Collecting tensorboard~=2.4\n",
      "  Using cached tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Using cached grpcio-1.32.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\oolus\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.27.0-py2.py3-none-any.whl (135 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\oolus\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\oolus\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (49.2.0.post20200714)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.1-py3-none-any.whl (12 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.1-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\oolus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\oolus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\oolus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\oolus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Installing collected packages: opt-einsum, tensorflow-estimator, protobuf, wrapt, flatbuffers, termcolor, tensorboard-plugin-wit, cachetools, pyasn1, pyasn1-modules, rsa, google-auth, grpcio, markdown, oauthlib, requests-oauthlib, google-auth-oauthlib, absl-py, tensorboard, keras-preprocessing, google-pasta, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed absl-py-0.11.0 cachetools-4.2.1 flatbuffers-1.12 google-auth-1.27.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.32.0 keras-preprocessing-1.1.2 markdown-3.3.3 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.15.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.1 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten,Conv2D,Dense,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTPybHxmm3jP"
   },
   "source": [
    "The initial building block of Keras is a model, and the simplest model is called `Sequential`. A sequential Keras model is a linear pipeline (a stack) of neural networks layers. This code fragment defines a single layer with 12 artificial neurons, and it expects 8 input features:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "O035kbH-m3jQ"
   },
   "outputs": [],
   "source": [
    "# Create a Single Layer Perceptron in Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer='random_uniform'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9e3YdgxFm3jQ"
   },
   "source": [
    "Each neuron can be initialized with specific weights. The most common choices provided by Keras:\n",
    "\n",
    "- `random_uniform`: Weights are initialized to uniformly random small values in (-0.05, 0.05). In other words, any value within the given interval is equally likely to be drawn.\n",
    "- `random_normal`: Weights are initialized according to a Gaussian, with a zero mean and small standard deviation of 0.05. For those of you who are not familiar with a Gaussian, think about a symmetric bell curve shape.\n",
    "- `zero`: All weights are initialized to zero.\n",
    "\n",
    "[Here](https://keras.io/initializations/) for the full list https://keras.io/initializations/ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoyuPYDmm3jQ"
   },
   "source": [
    "## Exercise 1\n",
    "\n",
    "Define a Single Layer Perceptron in Keras with 10 as dimension of the input and 8 neurons, with only zeros as initial weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "chiw3MsEm3jR"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=10, kernel_initializer='zero'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KG9TSntYm3jS"
   },
   "source": [
    "To make your model to output either 0 or 1, you have to add a line to your model:\n",
    "\n",
    "`model.add(Dense(1, activation='sigmoid'))`\n",
    "\n",
    "The output will be consider a neuron itself with the `sigmoid` as activation function.\n",
    "\n",
    "## Exercise 1.1\n",
    "\n",
    "Rewrite the Single Layer Perceptron defined in Exercise 1 so that it has the output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "FwTu4U7Nm3jS"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=10, kernel_initializer='zero'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4hBaGg7m3jT"
   },
   "source": [
    "As always, to test your model, you need some data. However, meanwhile you can see if your model has been built correctly inspecting it with `model.summary()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qrbV_c6am3jU",
    "outputId": "11056cbc-e90a-47a5-c6aa-25009afda001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 97\n",
      "Trainable params: 97\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Run this cell, the output should be as the one you see\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0TN9DPgoned"
   },
   "source": [
    "Now that you have successfully build a Keras model you have to *compile* it. This is where you have to define which **loss function** you want to use, which *optimizer* (not for today), and which **metrics** you want to check. \n",
    "\n",
    "Why we need to specify these?\n",
    "- The loss function is the \"error\", defined in a certain way, that your optimizer will try to minimize by updating the weights.\n",
    "- You have already seen the accuracy, precision and recall metrics. They are used for understanding when to stop the training and to review the training process, but they are not used by the optimizer.\n",
    "\n",
    "You can find some of the loss functions available in Keras here: https://keras.io/api/losses/\n",
    "\n",
    "Since the activation function used in the last layer is a sigmoid, it means that we are building a binary classifier, so we could use the:\n",
    "- `BinaryCrossentropy`: Computes the cross-entropy loss between true labels and predicted labels.\n",
    "Use this cross-entropy loss when there are only two label classes (assumed to be 0 and 1). For each example, there should be a single floating-point value per prediction.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Tjjz70EJm3jV"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKwpSOvBrWcN"
   },
   "source": [
    "If you didn't get an error, it means that your model has been successsfully compiled! Now it's time to train it! I'll give you a mock dataset to play with your model. But I want your attention here: *how should the input data look like?*\n",
    "\n",
    "Look at the input model: I asked for 10 input dimension and we output either 0 or 1. So we will have arrays of length 10 and binary labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "KkqDsMyqruge"
   },
   "outputs": [],
   "source": [
    "X = np.random.rand(1000,10)\n",
    "y = np.random.randint(0,2,size=(1000,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDFZyx8yte8I"
   },
   "source": [
    "Who's your best friend? ðŸ‘‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "n-1SdYmctQ4-"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7d7JRFft5Vb"
   },
   "source": [
    "Now... Get **fit**, stay (mentally) healthy (since you don't have to code this from scratch anymore)!\n",
    "\n",
    "The `fit` method is for actually training your model. So you have to define the number of `epochs` and the `batch_size`:\n",
    "\n",
    "- `epochs`: This is the number of times the model is exposed to the training set. At each iteration, the optimizer tries to adjust the weights so that the objective function is minimized.\n",
    "\n",
    "- `batch_size`: This is the number of training instances observed before the optimizer performs a weight update.\n",
    "\n",
    "\n",
    "Let's set the batch size to be 10 and the epochs 20! \n",
    "\n",
    "The cool thing is that you can even give a percentage of the training set as validation directly in the fit!!! This means that it will automatically test the error on the validation and gives you both the training accuracy and the validation accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "IVYA7GuAvHUs"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vNndDV16vO1R",
    "outputId": "a21a73a9-daad-488d-8a23-a86159138493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "54/54 [==============================] - 2s 12ms/step - loss: 0.6950 - accuracy: 0.5051 - val_loss: 0.6971 - val_accuracy: 0.4552\n",
      "Epoch 2/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.5042 - val_loss: 0.7014 - val_accuracy: 0.4552\n",
      "Epoch 3/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5299 - val_loss: 0.6989 - val_accuracy: 0.4552\n",
      "Epoch 4/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.5108 - val_loss: 0.6967 - val_accuracy: 0.4552\n",
      "Epoch 5/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4900 - val_loss: 0.6998 - val_accuracy: 0.4552\n",
      "Epoch 6/20\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5299 - val_loss: 0.6977 - val_accuracy: 0.4552\n",
      "Epoch 7/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6891 - accuracy: 0.5447 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5073 - val_loss: 0.6969 - val_accuracy: 0.4552\n",
      "Epoch 9/20\n",
      "54/54 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.5191 - val_loss: 0.6984 - val_accuracy: 0.4552\n",
      "Epoch 10/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6937 - accuracy: 0.4900 - val_loss: 0.6999 - val_accuracy: 0.4478\n",
      "Epoch 11/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.4826 - val_loss: 0.7028 - val_accuracy: 0.4552\n",
      "Epoch 12/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6912 - accuracy: 0.5266 - val_loss: 0.6983 - val_accuracy: 0.4328\n",
      "Epoch 13/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.5262 - val_loss: 0.6998 - val_accuracy: 0.4627\n",
      "Epoch 14/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6910 - accuracy: 0.5021 - val_loss: 0.6977 - val_accuracy: 0.4478\n",
      "Epoch 15/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5261 - val_loss: 0.6974 - val_accuracy: 0.4403\n",
      "Epoch 16/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4740 - val_loss: 0.6956 - val_accuracy: 0.4925\n",
      "Epoch 17/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.5236 - val_loss: 0.6959 - val_accuracy: 0.5000\n",
      "Epoch 18/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6918 - accuracy: 0.5394 - val_loss: 0.6976 - val_accuracy: 0.4627\n",
      "Epoch 19/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.5030 - val_loss: 0.7010 - val_accuracy: 0.4478\n",
      "Epoch 20/20\n",
      "54/54 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.4907 - val_loss: 0.7005 - val_accuracy: 0.4328\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rc0NAuNHwHKP"
   },
   "source": [
    "Now let's test on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0zLbMzTvz7u",
    "outputId": "ffe7d7df-f095-4178-9bdf-6181507efb79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 898us/step - loss: 0.6926 - accuracy: 0.5091\n",
      "loss: 0.6925823092460632\n",
      "accuracy 0.5090909004211426\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"{model.metrics_names[0]}:\", score[0])\n",
    "print(f\"{model.metrics_names[1]}\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DJnYfaN5wZ9t"
   },
   "source": [
    "The performance is super low because we gave random data! But you can try on real data!\n",
    "\n",
    "If you want to manually inspect the values of the prediction you can use the `predict` method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRITfUXgy_xJ",
    "outputId": "72ccd4c9-a0d0-459e-bc75-98a43c659e73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5146197]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "pred = model.predict(np.random.rand(1,10))\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5GGvRbYzVU8"
   },
   "source": [
    "As you can see, the output is a \"double\" array. So if you want to get the number inside it you could access it adding `[0][0]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "npoBW9UuzgUk",
    "outputId": "24a1845f-f269-4daf-afb5-aed0a9c6e413"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5146197"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwGpgvzx0DOp"
   },
   "source": [
    "But this is the a float! You want 0 or 1! True, you could round the prediction if you want, with threshold 0.5. Or use the predict_classes method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-WqSfPBgz6sW",
    "outputId": "08867881-2dce-41c1-d688-9e876640ce8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oolus\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "pred_classes = model.predict_classes(np.random.rand(1,10))\n",
    "pred_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oL6Gvqvvm3jV"
   },
   "source": [
    "Since the `predict_classes` method is deprecated, it's not convenient to use it for a maintainable code. So better to check the class manually using a threshold!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPS8OFe21NVE"
   },
   "source": [
    "# BIGGER NETWORKS\n",
    "\n",
    "You can add as many layers you(r RAM) want(s) in your neural network! Before we used only one! It's as simple as adding \n",
    "\n",
    "`model.add(Dense(N_HIDDEN))`\n",
    "\n",
    "between the the layers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "lUr6kXjf1LXt"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer='random_uniform'))\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oSliT7qD2aJ9",
    "outputId": "534c291d-f026-49a7-80ca-bcc00b1be830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               1300      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 1,509\n",
      "Trainable params: 1,509\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yuEn4pQ2kNo"
   },
   "source": [
    "The rest, is exactly the same of before!\n",
    "\n",
    "## Now it's your turn!\n",
    "\n",
    "I'll give you some input data, and I want you to create a neural network with:\n",
    "\n",
    "- `input_dim` : adeguate to fit the data I will provide you\n",
    "- 32 neurons in the input layer\n",
    "- 64 neurons in the first hidden layer\n",
    "- 32 neuron in the second hidden layer\n",
    "- a binary output layer with the sigmoid\n",
    "\n",
    "You're free to choose the rest of the parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "f7YzNg0r3P6z"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.rand(1000, 20)\n",
    "y = np.random.randint(0, 2, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vENjpH2e3M_N",
    "outputId": "53cc6f28-9d16-4ee2-cf17-4df9d23e1a03"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=10, kernel_initializer='random_uniform'))\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "QKvHjTh43tPr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,577\n",
      "Trainable params: 4,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=8, kernel_initializer='zeros'))\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,513\n",
      "Trainable params: 4,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=10, kernel_initializer='random_normal'))\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 4,577\n",
      "Trainable params: 4,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Easy Keras Exercises.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
